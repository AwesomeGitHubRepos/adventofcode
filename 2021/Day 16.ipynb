{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming binary format parsing\n",
    "\n",
    "- <https://adventofcode.com/2021/day/16>\n",
    "\n",
    "Part 1 is primarily a stream parsing task; given an input stream of hex digits, parse the stream into packets of data.\n",
    "\n",
    "I decided to unpack the hex value as a byte string; in Python the `bytes` type has a convenient [`fromhex()` method](https://docs.python.org/3/library/stdtypes.html#bytes.fromhex), and I made sure to pad the end of the input transmission string with an extra `0` if it didn't contain a multiple of 2 hex digits; that turned out not to be necessary for both the test and puzzle inputs. The reason I did this is because you can then index into the `bytes` object and Python gives you a 8-bit integer, ideal for applying bitwise operations to to extract the desired bits.\n",
    "\n",
    "Next, the class encapsulating the stream (the stream _reader_) tracks the position in the input stream of bytes, as well as an offset into the current byte so we can read data at the bit level. This requires that you use [bit shifting](https://en.wikipedia.org/wiki/Bitwise_operation#Bit_shifts) to move the target bits over to the right, as well as [bit masking](<https://en.wikipedia.org/wiki/Mask_(computing)#Masking_bits_to_0>) to turn off any other bits present in the byte. To make these operations that little bit more efficient I pre-compute those masks and shift counts based on the current bit offset into the byte. Of course, to read a given number of bits might well require that you look at multiple consecutive bytes, so the `StreamReader.read_bits()` method uses a loop and left-shifts to build up the resulting integer value from multiple bytes, as needed. If this was a real-world project, the reader would need to handle a transmission or read buffer, and handle the transmission or file running out of data prematurely, but for AoC we can ignore such trivial error-handling concerns.\n",
    "\n",
    "To read each type of packet (literal or operator), the stream reader delegates to the `BasePacket` class, passing in the stream reader. This class reads the 3 bits for the version + the 3 bits for the packet type, then _dispatches_ to the right packet subclass to handle reading the rest of the data. Given that part 1 was hand-wavy about the operator types not mattering _yet_ I anticipated that there'd be another 7 types of operator to handle later on, so I created a dispatch system based on registration via the [`object.__init_subclass__()` class hook](https://docs.python.org/3/reference/datamodel.html#object.__init_subclass__). This hook is called whenever a subclass of the class with such a hook is created, and allows you to set class-specific parameters via keyword arguments in a [`class <ClassName>(bases, ...)` statement](https://docs.python.org/3/reference/compound_stmts.html#class). If a specific packet subtype uses `type=<type_id>` in the class definition it'll be used for by the base packet class to read packet data, falling back to the generic `BaseOperatorPacket` class for unknown packet types that I am sure part 2 will tell us more about. This model lets you nicely compartmentalize reading of the packet types and their data, as well as handle reading the contained sub-packets for operators.\n",
    "\n",
    "Reading a literal then is simply a function of reading 5 bits in a loop, using the 4 right-most bits to build up the integer value (left-shifting the accumulating value by 4, add the new 4 bits after masking off the 5th bit), until the most-significant bit is 0.\n",
    "\n",
    "As isn't that un-common with data transmission formats that have been around for a while, there are multiple ways of expressing how much data you need to expect to read for recursively-embedded packets. The `1` variant (11 bits with a packet count) lets us just loop _count_ times and ask the stream reader to read the next packet, but for the `0` variant (15 bits counting out the number of bits the contained packets will take up) requires that all packets track their own size. As you read packets, you can then track if you have read enough data for all child packets that the operator packet covers. Tracking the size of a given packet is not hard, of course, just a little finnicky as you need to account for the initial 6 bits with the version number and type id, plus whatever bits are necessary to implement the packet type.\n",
    "\n",
    "Finally, a (cached) property takes care of exposing the version number sum; for literal packets, just return the `version` attribute, for operator packets, the version sum is that of their own `version` value plus the sum of all child `version_sum` values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from functools import cached_property\n",
    "from typing import ClassVar, Final, Iterator, TypeAlias, TypeVar\n",
    "\n",
    "T = TypeVar(\"T\", bound=\"BasePacket\")\n",
    "TypeId: TypeAlias = int\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BasePacket:\n",
    "    type: ClassVar[TypeId]\n",
    "    # dispatch table to read specific packet types\n",
    "    types: ClassVar[dict[TypeId, type[T]]] = {}\n",
    "\n",
    "    def __init_subclass__(cls: T, type: TypeId = None, **kwargs) -> None:\n",
    "        \"\"\"Register a subclass for dispatch on a specific packet type_id\"\"\"\n",
    "        if type is not None:\n",
    "            cls.type = type\n",
    "            BasePacket.types[type] = cls\n",
    "        super().__init_subclass__(**kwargs)\n",
    "\n",
    "    version: int\n",
    "    size: int  # in bits\n",
    "\n",
    "    @cached_property\n",
    "    def version_sum(self) -> int:\n",
    "        \"\"\"Sum of the version values for this packet and any sub-packets\"\"\"\n",
    "        return self.version\n",
    "\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        \"\"\"Part 2 expression value for this packet\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def _read(cls: type[T], version: int, stream: StreamReader) -> T:\n",
    "        \"\"\"Read data for single packet from the stream\n",
    "\n",
    "        The version and type have already been read, subclasses should implement\n",
    "        how each packet type data is to be read from the stream, and create the\n",
    "        specific packet instance.\n",
    "\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @classmethod\n",
    "    def from_stream(cls, stream: StreamReader) -> BasePacket:\n",
    "        \"\"\"Read the next packet from the stream reader\n",
    "\n",
    "        Dispatches to specific packet types based on the type_id read from the\n",
    "        stream, falling back to BaseOperatorPacket if no specific type subclass\n",
    "        is found.\n",
    "\n",
    "        \"\"\"\n",
    "        version, type_id = stream.read_bits(3), stream.read_bits(3)\n",
    "        return BasePacket.types.get(type_id, BaseOperatorPacket)._read(version, stream)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class BaseOperatorPacket(BasePacket):\n",
    "    children: tuple[BasePacket]\n",
    "\n",
    "    @property\n",
    "    def version_sum(self) -> int:\n",
    "        return self.version + sum(child.version_sum for child in self.children)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Number of child packets contained\"\"\"\n",
    "        return len(self.children)\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        \"\"\"Part 2: iterate over the expression value of each child packet\"\"\"\n",
    "        yield from (child.expression_value for child in self.children)\n",
    "\n",
    "    def __getitem__(self, i: int) -> int:\n",
    "        \"\"\"Part 2: get the expression value of the ith child packet\"\"\"\n",
    "        return self.children[i].expression_value\n",
    "\n",
    "    @classmethod\n",
    "    def _read(cls: type[T], version: int, stream: StreamReader) -> T:\n",
    "        \"\"\"Read operator packet and containd child packets from the stream\n",
    "\n",
    "        The number of subpackets read is determined from the first bit following\n",
    "        the version and type_id bits. Ff 0, read a 15-bit length value from the\n",
    "        stream, then read child packets until their total bit size is equal to\n",
    "        that length value. If 1, read an 11-bit child packet count, then read\n",
    "        child packet count number of packets from the stream.\n",
    "\n",
    "        \"\"\"\n",
    "        length_type_id = stream.read_bits(1)\n",
    "        size = 7  # version + type + flag bits\n",
    "        subpackets = []\n",
    "        if length_type_id == 0:\n",
    "            # length is in bits\n",
    "            packet_length = stream.read_bits(15)\n",
    "            size += 15 + packet_length\n",
    "            while packet_length:\n",
    "                sub = next(stream)\n",
    "                packet_length -= sub.size\n",
    "                subpackets.append(sub)\n",
    "            assert packet_length == 0\n",
    "        else:\n",
    "            # length is in packets\n",
    "            packet_count = stream.read_bits(11)\n",
    "            size += 11\n",
    "            for _ in range(packet_count):\n",
    "                sub = next(stream)\n",
    "                size += sub.size\n",
    "                subpackets.append(sub)\n",
    "        return cls(version, size, tuple(subpackets))\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class LiteralPacket(BasePacket, type=4):\n",
    "    value: int\n",
    "\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        \"\"\"Part 2 expression value for this packet is the literal value\"\"\"\n",
    "        return self.value\n",
    "\n",
    "    @classmethod\n",
    "    def _read(cls, version: int, stream: StreamReader) -> LiteralPacket:\n",
    "        \"\"\"Read a literal value packet\n",
    "\n",
    "        Reads groups of 5 bits, containing a continuation bit and 4 bits\n",
    "        for the literal value. Reading continues until the continuation bit\n",
    "        is 0.\n",
    "\n",
    "        \"\"\"\n",
    "        value = 0\n",
    "        size = 6  # length of version + type bits\n",
    "        while True:\n",
    "            chunk = stream.read_bits(5)\n",
    "            size += 5\n",
    "            value = (value << 4) | (chunk & 0xF)\n",
    "            if not chunk & 0x10:\n",
    "                break\n",
    "        return cls(version, size, value)\n",
    "\n",
    "\n",
    "# pre-computed bitmasks and right-shift amount to extract a certain number of\n",
    "# bits from a byte, given the bit offset (0-7) and the number of bits to extract\n",
    "# (1-8).\n",
    "MASKS: Final[dict[tuple[int, int, int], tuple[int, int]]] = {\n",
    "    (offset, count): ((2**count - 1) << (8 - offset - count), 8 - offset - count)\n",
    "    for offset in range(8)\n",
    "    for count in range(1, 9)\n",
    "    if count + offset <= 8\n",
    "}\n",
    "\n",
    "\n",
    "class StreamReader:\n",
    "    def __init__(self, stream: bytes) -> None:\n",
    "        self.stream = stream\n",
    "        self.pos = 0  # byte position in stream\n",
    "        self.bit_pos = 0  # offset into current byte (0-7)\n",
    "\n",
    "    @classmethod\n",
    "    def from_string(cls, s: str) -> StreamReader:\n",
    "        # if the input length doesn't align to full bytes, pad with a 0\n",
    "        # and start reading at the second nibble.\n",
    "        if len(s) % 2:\n",
    "            s += \"0\"\n",
    "        return cls(bytes.fromhex(s))\n",
    "\n",
    "    def read_bits(self, count: int) -> int:\n",
    "        result = 0\n",
    "        bpos, pos, stream = self.bit_pos, self.pos, self.stream\n",
    "        while count:\n",
    "            bcount = min(count, 8 - bpos)\n",
    "            count -= bcount\n",
    "            result <<= bcount\n",
    "            mask, shift = MASKS[bpos, bcount]\n",
    "            result |= (stream[pos] & mask) >> shift\n",
    "            bpos += bcount\n",
    "            if bpos == 8:\n",
    "                bpos = 0\n",
    "                pos += 1\n",
    "        self.bit_pos, self.pos = bpos, pos\n",
    "        return result\n",
    "\n",
    "    def __iter__(self) -> Iterator[BasePacket]:\n",
    "        return self\n",
    "\n",
    "    def __next__(self) -> BasePacket:\n",
    "        return BasePacket.from_stream(self)\n",
    "\n",
    "\n",
    "tests = {\n",
    "    \"D2FE28\": 6,\n",
    "    \"38006F45291200\": 9,\n",
    "    \"EE00D40C823060\": 14,\n",
    "    \"8A004A801A8002F478\": 16,\n",
    "    \"620080001611562C8802118E34\": 12,\n",
    "    \"C0015000016115A2E0802F182340\": 23,\n",
    "    \"A0016C880162017C3686B18A3D4780\": 31,\n",
    "}\n",
    "\n",
    "for test_input, expected in tests.items():\n",
    "    assert next(StreamReader.from_string(test_input)).version_sum == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: 901\n"
     ]
    }
   ],
   "source": [
    "import aocd\n",
    "\n",
    "transmission = aocd.get_data(day=16, year=2021)\n",
    "print(\"Part 1:\", next(StreamReader.from_string(transmission)).version_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: executing the operators\n",
    "\n",
    "Now that we can decode packets, we can define the operators; all I had to do was provide implementations of each operator type. I did have to update part 1 to give the my classes a notion of _expression values_, and I expanded the `BaseOperatorPacket` class some additional Python magic methods to implement indexing and iteration over the expression values of the contained child packets, but I could have done the same with mixin classes; it would just have been a lot more verbose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "class OpSum(BaseOperatorPacket, type=0):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        return sum(self)\n",
    "\n",
    "\n",
    "class OpProduct(BaseOperatorPacket, type=1):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        return reduce(operator.mul, self)\n",
    "\n",
    "\n",
    "class OpMinimum(BaseOperatorPacket, type=2):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        return min(self)\n",
    "\n",
    "\n",
    "class OpMaximum(BaseOperatorPacket, type=3):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        return max(self)\n",
    "\n",
    "\n",
    "class OpGreaterThan(BaseOperatorPacket, type=5):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        assert len(self.children) == 2\n",
    "        return int(self[0] > self[1])\n",
    "\n",
    "\n",
    "class OpLessThan(BaseOperatorPacket, type=6):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        assert len(self.children) == 2\n",
    "        return int(self[0] < self[1])\n",
    "\n",
    "\n",
    "class OpEqualTo(BaseOperatorPacket, type=7):\n",
    "    @cached_property\n",
    "    def expression_value(self) -> int:\n",
    "        assert len(self.children) == 2\n",
    "        return int(self[0] == self[1])\n",
    "\n",
    "\n",
    "expression_tests = {\n",
    "    \"C200B40A82\": 3,\n",
    "    \"04005AC33890\": 54,\n",
    "    \"880086C3E88112\": 7,\n",
    "    \"CE00C43D881120\": 9,\n",
    "    \"D8005AC2A8F0\": 1,\n",
    "    \"F600BC2D8F\": 0,\n",
    "    \"9C005AC2F8F0\": 0,\n",
    "    \"9C0141080250320F1802104A08\": 1,\n",
    "}\n",
    "for test_input, expected in expression_tests.items():\n",
    "    assert next(StreamReader.from_string(test_input)).expression_value == expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 2: 110434737925\n"
     ]
    }
   ],
   "source": [
    "print(\"Part 2:\", next(StreamReader.from_string(transmission)).expression_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with real-world data streams\n",
    "\n",
    "Todays exercise is quite a good model for how real-world binary formats work. They usually do not pack data into such odd bit counts however; computers work much more efficiently with data packed into (powers of 2 of multples of) bytes. Individual bytes can still contain multiple pieces of information such as 1 bit flags or several smaller integer values.\n",
    "\n",
    "## Continuation flags\n",
    "\n",
    "The continuation bit set in the literal value format is exactly how a range of variable-width encodings work, such as [UTF-8](https://en.wikipedia.org/wiki/UTF-8). Some formats, like UTF-8, use multiple bits to handle continuation signalling (in UTF-8, the number of bits for this purpose is _variable too_, from 1 to 5). The advantage of such a format is that you can encode complex data into a much more compact form than if you used a fixed number of bytes for every possible value you encode, but the disadvantage is that you can't just index into a stream to get to a specific Nth value. For UTF-8, you can encode ASCII text (e.g. the majority of textual computer data in the western world) in just 1 byte per character, increasing to 2 bytes for most [Latin-script alphabets](https://en.wikipedia.org/wiki/Latin-script_alphabet), while 3 bytes covers the remainder of the [Unicode Basic Multilingual Plane](<https://en.wikipedia.org/wiki/Plane_(Unicode)#Basic_Multilingual_Plane>) (BMP) and you only need 4 bytes for Unicode data beyond the BMP. But, if you need to index into a UTF-8 byte string, you'll have to look at the first 4 bits of a lot of the bytes between the start of such a stream and the Nth codepoint you want to skip to (rule of thumb: left-most-bit not set? Then move on to the next byte, otherwise count consecutive left-most bits that are `1` and skip that many times minus 1).\n",
    "\n",
    "## Sub-packet size expressed in total length or a count\n",
    "\n",
    "The operator packets record either the total length of the subpackets (in bits, real-world formats are far more likely to record a byte count), or a number of packets. For formats with a variable packet length, those two numbers have very different consequences for how you read such a stream, and both have advantages and disadvantages. Because of this many formats will use both, depending on what kind of information is encoded!\n",
    "\n",
    "A fixed size lets you skip over to the next packet in one big step, while a packet count requires that you read each sub-packet in turn, or at least enough to be able to skip the rest of that packet. But, a fixed size requires that the _encoder_ knows what size it is going to be sending, _up front_, and not all data streams lend themselves to this. For a streaming video format, for example, the encoder might not know how well later video data will compress and so won't know how many packets it'll end up sending. But such an encoder will pull in video data to encode in chunks, and may well know that it is going to send N frames of video, each of variable size, and tell the decoder on the other end to expect N sub packets.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8bb5fd587ebf4d90f905285c44a569046664a8863ee065ff2dd968491b671e06"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit ('adventofcode-mOkh6lsX': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
